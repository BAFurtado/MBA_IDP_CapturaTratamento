{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Aula4.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Técnicas Avançadas de **Captura e Tratamento** de Dados\n",
    "\n",
    "---\n",
    "## Prof. Bernardo Alves Furtado\n",
    "---\n",
    "### MBA em Big Data, Business Analytics e Gestão de Negócios. @**IDP**\n",
    "\n",
    "3 a 21 agosto  -- 21 horas/aula"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Recuperando elementos da última aula:\n",
    "# `class`\n",
    "\n",
    "1. https://sites.google.com/view/bernardo-alves-furtado/presentations\n",
    "\n",
    "PDF apresentação sobre `class`\n",
    "2. https://drive.google.com/file/d/1XmhDXW_dI3qS23bse0p9TUCUa__nxiq9/view?usp=sharing\n",
    "\n",
    "# Exercício Lucas. API. Post"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'https://pastebin.com/aZ8gfCC1'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# Exemplo\n",
    "\n",
    "# Chave da API\n",
    "API_KEY = \"bISrNciS0j0yT4WGEWHnkj6cuhs1eZw6\"\n",
    "\n",
    "# Endereço que enviaremos os dados\n",
    "API_ENDPOINT = \"https://pastebin.com/api/api_post.php\"\n",
    "\n",
    "# Esse é o código que queremos enviar\n",
    "source_code = '''\n",
    "class MyFirstClass:\n",
    "    def __init__(self, _id):\n",
    "        self.id = _id\n",
    "        print('This is my first class')\n",
    "        print(f'This is object {self.id}')\n",
    "\n",
    "for i in range(5):\n",
    "    MyFirstClass(i)\n",
    "'''\n",
    "# O \"data\" tem tudo que\n",
    "data = {'api_dev_key':API_KEY,\n",
    "        'api_option':'paste',\n",
    "        'api_method':'post',\n",
    "        'api_paste_code':source_code,\n",
    "        'api_paste_format':'python'}\n",
    "\n",
    "# Post dos nossos dados\n",
    "r = requests.post(url=API_ENDPOINT, data=data)\n",
    "r.text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Boa prática: robots.txt\n",
    "\n",
    "No exempĺo da aula passada de PDF, os resultados de um concurso público, são públicos e podem ser conferidos por qualquer parte\n",
    "interessada.\n",
    "\n",
    "O agente que divulga a informação pode fazê-lo por meio de um PDF (talvez mais simples ou imediato),\n",
    "ou pode fazê-lo também com uma simples planilha.\n",
    "\n",
    "Portanto, a leitura dos dados está em consonância com o caráter público da sua divulgação.\n",
    "\n",
    "O mesmo acontece (deveria acontecer) com os DIÁRIOS OFICIAIS, ou com as informações dos cartórios, por exemplo.\n",
    "\n",
    "---\n",
    "\n",
    "Nos sites, o arquivo **robots.txt** é uma maneira padrão de informar (não exige, apenas informa) ao\n",
    "usuário o que *spider, crawler, robôs* podem ou não realizar em determinado site. O chamado *Robots Exclusion Protocol*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exemplo. source: (Jarmul e Lawson, 2017)\n",
    "\n",
    "# section 1\n",
    "# User-agent: BadCrawler\n",
    "# Disallow: /"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Disallow: /` restringe todo o conteúdo do site a robôs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# section 2\n",
    "# User-agent: *\n",
    "# Crawl-delay: 5\n",
    "# Disallow: /trap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Crawl-delay recomenda que o robô pause entre pedidos de request"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# section 3\n",
    "# Sitemap: https://economia.uol.com.br/sitemap/v2/201902.xml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Além das regras, o robots.txt pode conter o link para o arquivo XML que fornece a estrutura da página.\n",
    "\n",
    "Esta informação já pode ser útil, por exemplo, para quem busca por títulos de notícias para associar a preços de ativos, por exemplo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Outro exemplo:\n",
    "\n",
    "# robots.txt for http://www.folha.com.br/\n",
    "# Contact webmaster@grupofolha.com.br if you have questions regarding this file\n",
    "\n",
    "# User-agent: *\n",
    "# Disallow: /cgi-bin/\n",
    "# Disallow: /folha/\n",
    "# Disallow: /guia/\n",
    "# Disallow: /logs/\n",
    "# Disallow: /simulador/\n",
    "#\n",
    "# User-agent: Googlebot-News\n",
    "# Allow: *\n",
    "#\n",
    "# User-agent: Twitterbot\n",
    "# Disallow: /virtual/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# APIs 0\n",
    "## Request: exemplo simplista"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check: https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/apis-in-python/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://economia.uol.com.br'\n",
    "response = urllib.request.urlopen(url)\n",
    "response.status"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "soup = BS(response, 'html5lib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "some_results = soup.find_all('section', {'class': 'highlights-headline'})\n",
    "print(some_results[0].text.strip())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "Na prática\n",
    "# APIs I\n",
    "\n",
    "\"*Uma API define uma sintaxe padronizada que permite a um software se comunicar com\n",
    "outro, mesmo que tenham sido escritos em linguagens diferentes ou\n",
    "estejam estruturados de modo distinto.*\" (Mitchel, 2019, p. 201)\n",
    "\n",
    "## Ilustração: lat, long"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituto Brasiliense de Direito Público, SGAS - Quadra 607, SQS 407, Asa Sul, Brasília, Plano Piloto, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70422-900, Brasil\n",
      "lat: -15.821596, long: -47.894647\n",
      "Instituto de Pesquisa Econômica Aplicada, SBS Quadra 01, Setor Bancário Sul, Brasília, Plano Piloto, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70070-120, Brasil\n",
      "lat: -15.798409, long: -47.880742\n",
      "Conselho Nacional de Desenvolvimento Científico e Tecnológico, Estrada Parque Dom Bosco, Lago Sul, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70210000, Brasil\n",
      "lat: -15.859079, long: -47.927222\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "places = 'IDP', 'Ipea', 'CNPq'\n",
    "\n",
    "\n",
    "def lat_long(locais):\n",
    "    for local in locais:\n",
    "        address = f'{local}, Brasília, Brazil'\n",
    "        url = 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(address) +'?format=json'\n",
    "        response = requests.get(url).json()\n",
    "        # Note que para cada local uma response é gerada.\n",
    "        # Como poderíamos armazenar essas informações?\n",
    "        print(response[0]['display_name'])\n",
    "        lat = float(response[0]['lat'])\n",
    "        long = float(response[0]['lon'])\n",
    "        print(f'lat: {lat:.8}, long: {long:.8}')\n",
    "\n",
    "\n",
    "lat_long(places)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercício rápido.\n",
    "\n",
    "1. Calcule a distância linear da sua casa ao IDP.\n",
    "2. Crie um local novo: 'SQS 402', ou o seu endereço.\n",
    "3. Adicione no address completo (cidade, país)\n",
    "4. Use o código acima\n",
    "5. Use teorema de pitágoras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Tip.\n",
    "# Convert to meters by multiplying it to  111,139. (111 mil)\n",
    "def calculate_distancia_in_meters(x1, y1, x2, y2):\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** .5 * 111139\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def lat_long2(place):\n",
    "    address = f'{place}, Brasília, Brazil'\n",
    "    url = 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(address) +'?format=json'\n",
    "    response = requests.get(url).json()\n",
    "    try:\n",
    "        print(response[0]['display_name'])\n",
    "        return float(response[0]['lat']), float(response[0]['lon'])\n",
    "    except IndexError:\n",
    "        print(f'Place not found {place}!')\n",
    "        return False, False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def distance(place1, place2):\n",
    "    x1, y1 = lat_long2(place1)\n",
    "    x2, y2 = lat_long2(place2)\n",
    "    if all([x1, y1, x2, y2]):\n",
    "        print(f'Distância estimada de {calculate_distancia_in_meters(x1, y1, x2, y2)/1000:.2f} km')\n",
    "    else:\n",
    "        print('Not all places were found')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instituto Brasiliense de Direito Público, SGAS - Quadra 607, SQS 407, Asa Sul, Brasília, Plano Piloto, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70422-900, Brasil\n",
      "SQN 216, Brasília, Plano Piloto, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70875510, Brasil\n",
      "Distância estimada de 9.37 km\n"
     ]
    }
   ],
   "source": [
    "p1 = 'IDP'\n",
    "p2 = 'SQN 216'\n",
    "\n",
    "distance(p1, p2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# APIs II"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = 'https://queridodiario.ok.org.br/api/'\n",
    "endpoint = 'gazettes/'\n",
    "\n",
    "params = {'since': '2020-12-15',\n",
    "          'until': '2020-12-31',\n",
    "          'keywords': ['pandemia']}\n",
    "\n",
    "r = requests.get(f'{url}{endpoint}', params=params).json()\n",
    "r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(r.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(r['gazettes']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(r['gazettes'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(r['gazettes'][0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gazette in r['gazettes']:\n",
    "    try:\n",
    "        texto = gazette['file_raw_txt']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    finally:\n",
    "        break\n",
    "\n",
    "texto"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = urllib.request.urlopen(texto)\n",
    "response.status"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt = BS(response, 'html5lib')\n",
    "txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Exercício II\n",
    "\n",
    "1. Utilize o modelo acima.\n",
    "2. Consulte as regras da API dos Diários Oficiais dos municípios:\n",
    "\n",
    "https://queridodiario.ok.org.br/api/docs#/default/Get_gazettes_gazettes__get\n",
    "\n",
    "3. Construa outro dicionário de parâmetros, de acordo com seus interesses, como o exemplo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {'since': '2020-12-15',\n",
    "          'until': '2020-12-31',\n",
    "          'keywords': ['pandemia']}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Faça o request e avalie o resultado.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exemplo 2. APIs Diários\n",
    "url = 'https://queridodiario.ok.org.br/api/'\n",
    "endpoint = 'gazettes/'\n",
    "\n",
    "# Territory ID: Rio de Janeiro\n",
    "params = {'territory_id': '3304557',\n",
    "          'since': '2020-01-01',\n",
    "          'until': '2020-12-31',\n",
    "          'keywords': ['ITBI']}\n",
    "\n",
    "r = requests.get(f\"{url}{endpoint}/{params['territory_id']}\", params=params).json()\n",
    "r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# APIs III\n",
    "## Serious illustration\n",
    "\n",
    "### Passo-a-passo\n",
    "1. https://developer.twitter.com/en/docs/tutorials/step-by-step-guide-to-making-your-first-request-to-the-twitter-api-v2\n",
    "\n",
    "Depois, esse:\n",
    "\n",
    "2. https://github.com/twitterdev/Twitter-API-v2-sample-code\n",
    "\n",
    "Nem tudo é possível, por exemplo, limitado aos últimos 7 dias. Para detalhes, veja:\n",
    "\n",
    "3. https://developer.twitter.com/en/docs/twitter-api/early-access"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "bearer_token = getpass()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "#\n",
    "# twitter_handle = 'furtadobb'\n",
    "# twitter_handle = 'SejaIDP'\n",
    "# twitter_handle = 'Reguffe'\n",
    "twitter_handle = 'folha'\n",
    "\n",
    "# start_time = '2021-07-29T00:00:00Z'\n",
    "# end_time = '2021-08-02T00:00:00Z'\n",
    "query_params = {'query': f'(from:{twitter_handle})',\n",
    "                'tweet.fields': 'author_id'}\n",
    "\n",
    "\n",
    "def bearer_oauth(bear):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    bear.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    bear.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return bear\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def main():\n",
    "    json_response = connect_to_endpoint(search_url, query_params)\n",
    "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    return json_response\n",
    "\n",
    "exemplo_json = main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercício\n",
    "\n",
    "1. Note que pelas regras do Twitter, o plano grátis inclui somente os últimos 7 dias.\n",
    "2. Quais seriam os passos necessários para que uma base de dados acumulasse, ao longo de um mês, por exemplo,\n",
    "todos os *tweets*?\n",
    "3. Considerando o exemplo abaixo como um objeto `python` (`dict`), como poderíamos automatizar o processo atualização\n",
    "da base?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_response_exemplo = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"author_id\": \"14594813\",\n",
    "            \"id\": \"1420089179690737668\",\n",
    "            \"text\": \"O ato contra a est\\u00e1tua em S\\u00e3o Paulo ocorre num momento em que h\\u00e1 um questionamento global sobre homenagens a figuras controversas \\u2014como \\u00e9 o caso dos bandeirantes, que atuavam na manuten\\u00e7\\u00e3o da escravid\\u00e3o e na persegui\\u00e7\\u00e3o aos ind\\u00edgenas no Brasil colonial https://t.co/0lfHQjlUR4 https://t.co/2DP40F6gra\"\n",
    "        },\n",
    "        {\n",
    "            \"author_id\": \"14594813\",\n",
    "            \"id\": \"1420086844637728777\",\n",
    "            \"text\": \"L\\u00edderes do The Who, Pete Townshend e Roger Daltrey, trocam alfinetadas em livros https://t.co/zktrgs8X3Z\"\n",
    "        },\n",
    "        {\n",
    "            \"author_id\": \"14594813\",\n",
    "            \"id\": \"1420074263617417221\",\n",
    "            \"text\": \"Mudan\\u00e7a de governo no Haiti n\\u00e3o deve transformar vida da popula\\u00e7\\u00e3o, dizem haitianos https://t.co/9qP635znaa\"\n",
    "        },\n",
    "        {\n",
    "            \"author_id\": \"14594813\",\n",
    "            \"id\": \"1420073763643830275\",\n",
    "            \"text\": \"Com reforma, Bolsonaro consolida 27 trocas na Esplanada dos Minist\\u00e9rios em dois anos e meio https://t.co/r2kv1TmtzU\"\n",
    "        }\n",
    "    ],\n",
    "    \"meta\": {\n",
    "        \"newest_id\": \"1420089179690737668\",\n",
    "        \"next_token\": \"b26v89c19zqg8o3fpdm6gluv37fhc1o08leaaw7iwmmwt\",\n",
    "        \"oldest_id\": \"1420073763643830275\",\n",
    "        \"result_count\": 10\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Vamos investigar o JSON (dict) de retorno. Veja que há duas *keys* no dicionário de resultados."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_response_exemplo.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 'meta' sempre contém as fronteiras em termos de _id (newest, oldest) e o 'next_token' que é o endereço da próxima página\n",
    "3. Teremos que sistematizar o download de todos os tweets, até que 'next_token' seja null\n",
    "4. E teremos que tornar persistente uma database para que mantenha os tweets com mais de 7 dias na base, a partir do oitavo dia, certo?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Portanto, será necessário\n",
    "1. Criar uma base e salvá-la\n",
    "2. A cada novo processo/dia:\n",
    "    1. Ler/abrir a base\n",
    "    2. Ler os novos tweets\n",
    "    3. Verificar se os tweets já existem na base\n",
    "    4. Caso negativo, adicioná-los\n",
    "\n",
    "3. Salvar novamente a base\n",
    "\n",
    "**10 minutos para pensarem um pouco antes da resolução**\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. Atualizando os parâmetros da *query*. Garantindo o token."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "twitter_handle = 'folha'\n",
    "\n",
    "query_params = {'query': f'(from:{twitter_handle})',\n",
    "                'tweet.fields': 'author_id'}\n",
    "\n",
    "bearer_token = getpass()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Criação base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'data'\n",
    "filename = 'base_tweets.csv'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "filename = os.path.join(path, filename)\n",
    "cols_names = ['author_id', 'id', 'text']\n",
    "\n",
    "base = pd.DataFrame(columns=cols_names)\n",
    "base.to_csv(filename, sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Modificando somente a função `main()` para realizar várias leituras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main(database, path):\n",
    "    next_token = True\n",
    "    # Fazendo a leitura, enquanto existir 'next_token' na resposta\n",
    "    while next_token:\n",
    "        # Realizar a conexão com os parâmetros já estabelecidos\n",
    "        json_response = connect_to_endpoint(search_url, query_params)\n",
    "        # Atualizar o valor do next_token, de acordo com a resposta\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            # Conferindo a atualização realizada\n",
    "            print(next_token)\n",
    "            # Atualizando para a conexão que precisamos capturar a página seguinte\n",
    "            query_params['next_token'] = next_token\n",
    "        else:\n",
    "            next_token = False\n",
    "        # Atualizando o DataFrame em si.\n",
    "        # 1. Sabemos que o retorno tem duas keys. A key data, que contém uma lista de dicionários, precisa ser lida.\n",
    "        # 2. Uma vez lida, é adicionada à base existente\n",
    "        database = database.append(base.from_dict(x for x in json_response['data']))\n",
    "        # A título de exemplo, vamos interromper a leitura após maia de 10 leituras\n",
    "        # if len(database) > 20:\n",
    "        #     break\n",
    "    # Salvamos a base\n",
    "    database.to_csv(path, sep=';', index=False)\n",
    "    return database\n",
    "\n",
    "base = pd.read_csv(filename, sep=';')\n",
    "tweet_base = main(base, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Agora atualizando o exercício para o dia seguinte.\n",
    "4. Temos que verificar a *id* do nosso tweet mais recente da base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main(database, path):\n",
    "    next_token = True\n",
    "    # Note que a condição abaixo é necessária para verificar se há algum item com id na base\n",
    "    if database.id.max():\n",
    "        # Caso afirmativo, adicione o mais recente nos parâmetros da query\n",
    "        query_params['since_id'] = database.id.max()\n",
    "    while next_token:\n",
    "        json_response = connect_to_endpoint(search_url, query_params)\n",
    "        # Verificando se é necessária mais de uma conexão, ou se já é a última ou única.\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(next_token)\n",
    "            query_params['next_token'] = next_token\n",
    "        else:\n",
    "            next_token = False\n",
    "        if 'data' in json_response:\n",
    "            # Novamente. json_response['data'] é uma lista.\n",
    "            # Vamos precisar dos dicionários que estão dentro da lista.\n",
    "            database = database.append(database.from_dict(x for x in json_response['data']))\n",
    "        # if len(database) > 20:\n",
    "        #     break\n",
    "    database.to_csv(path, sep=';', index=False)\n",
    "    return database\n",
    "\n",
    "\n",
    "base = pd.read_csv(filename, sep=';')\n",
    "tweet_base = main(base, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Reforçando Captura $+$ Base de Dados\n",
    "# Exercício II API $+$ SQL\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Seguindo exatamente os passos que utilizamos para ilustrar SQL, vamos simplificar o processo e\n",
    "criar uma base que atenda os requisitos desta captura de dados de tweets.\n",
    "\n",
    "**10 minutos para voltarem ao exercício anterior e se familiarizarem novamente com os passos necessários**\n",
    "\n",
    "... e me contarem quais passos são esses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def countdown(t):\n",
    "    while t:\n",
    "        print(f'Faltando...: {t} segundos')\n",
    "        time.sleep(60)\n",
    "        t -= 60\n",
    "    print('Comecemos!')\n",
    "\n",
    "minutes = 10\n",
    "countdown(minutes * 60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Brincando de python de forma útil...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Vamos começar **CRIANDO** a função de conexão com uma base nova. E o nome da nova base."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Configuração de dados básicos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Endereço no qual irá guardar a database\n",
    "tweet_db = 'data/my_first_tweet_database.db'\n",
    "\n",
    "# Relembrando dados básicos\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "twitter_handle = 'folha'\n",
    "query_params = {'query': f'(from:{twitter_handle})',\n",
    "                'tweet.fields': 'author_id'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Função genérica de conexão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def connect_db(database):\n",
    "    conn = sqlite3.connect(database)\n",
    "    print(f'Conexão realizada com sucesso.')\n",
    "    return conn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Na sequência, vamos adaptar os comandos **SQL** para a CRIAÇÃO DE TABELAS na base nova.\n",
    "\n",
    " * Como exemplo, vamos fazer só uma tabela. Sugiro realizarem de forma mais completa posteriormente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sql_create_table = \"\"\"CREATE TABLE IF NOT EXISTS tweets (\n",
    "                                id integer PRIMARY KEY,\n",
    "                                texto text NOT NULL,\n",
    "                                author_id NOT NULL\n",
    "                            );\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Com a função de conexão, o nome da base e a instrução para criação da tabela, vamos DE FACTO, criar a tabela.\n",
    " * Simplesmente passa o nome da base, executa o comando de criar tabela e *commit* (salva localmente)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rode somente uma vez para criar a table.\n",
    "with connect_db(tweet_db) as con:\n",
    "    con.execute(sql_create_table)\n",
    "    con.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Agora a parte distinta do exemplo anterior. Temos que inserir o processo de ATUALIZAÇÃO da base SQL ao processo de consulta da API!\n",
    "7. Vamos utilizar a mesma função `main` anterior, porém, **alterando**:\n",
    " 1. No momento de atualização da base.\n",
    " 2. E na consulta ao valor máximo presente na base."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def insere_tweet(conn, tweet):\n",
    "    sql = ''' INSERT INTO tweets(author_id,id,texto)\n",
    "              VALUES(?,?,?) '''\n",
    "    cur = conn.cursor()\n",
    "    # Note que 'tweet' precisa ser recebido como uma lista com sequência de id, author_id e texto\n",
    "    cur.executemany(sql, tweet)\n",
    "    conn.commit()\n",
    "    return cur.lastrowid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_since_id(conn):\n",
    "    sql = '''SELECT MAX(id) FROM tweets;'''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    return cur.fetchone()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main(database):\n",
    "    # Abre a conexão com SQL\n",
    "    with connect_db(database) as conn:\n",
    "        next_token = True\n",
    "        # # Note que a condição abaixo é necessária para verificar se há algum item com id na base\n",
    "        # if database.id.max():\n",
    "        #     # Caso afirmativo, adicione o mais recente nos parâmetros da query\n",
    "        #     query_params['since_id'] = database.id.max()\n",
    "        while next_token:\n",
    "            # Verificando se o tweet mais recente já está na base\n",
    "            max_value = check_since_id(con)\n",
    "            if max_value:\n",
    "                query_params['since_id'] = max_value\n",
    "            json_response = connect_to_endpoint(search_url, query_params)\n",
    "            # Verificando se é necessária mais de uma conexão, ou se já é a última ou única.\n",
    "            if 'next_token' in json_response['meta']:\n",
    "                next_token = json_response['meta']['next_token']\n",
    "                print(next_token)\n",
    "                query_params['next_token'] = next_token\n",
    "            else:\n",
    "                next_token = False\n",
    "            if 'data' in json_response:\n",
    "                # Novamente. json_response['data'] é uma lista.\n",
    "                # Vamos precisar dos dicionários que estão dentro da lista.\n",
    "                tweets = [list(x.values()) for x in json_response['data']]\n",
    "                insere_tweet(conn, tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chama a função com a database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main(tweet_db)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}